{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10edbb53",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c1e2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, LassoCV, ElasticNet, ARDRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fdf8e",
   "metadata": {},
   "source": [
    "# 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e834b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/train.parquet\")\n",
    "X = train.drop(['label'], axis=1)\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd504e9",
   "metadata": {},
   "source": [
    "# 3. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158858ec",
   "metadata": {},
   "source": [
    "## 3.1 Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b386ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ytrue_vs_ypred(y_true, y_pred, title=\"Predicted vs Actual\"):\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "    plt.plot([y_true.min(), y_true.max()], \n",
    "             [y_true.min(), y_true.max()], \n",
    "             'r--', lw=2)\n",
    "    plt.xlabel(\"Actual (y_true)\")\n",
    "    plt.ylabel(\"Predicted (y_pred)\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def scorer(y_pred, y_true, label=\"\", verbose=True, plot=False, return_metric=\"r2\"):\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Regression Report for: \" + label)\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "    if plot:\n",
    "        plot_ytrue_vs_ypred(y_true, y_pred)\n",
    "\n",
    "    if return_metric == \"r2\":\n",
    "        return r2\n",
    "    elif return_metric == \"mae\":\n",
    "        return mae\n",
    "    elif return_metric == \"mse\":\n",
    "        return mse\n",
    "    else:\n",
    "        raise ValueError(\"return_metric must be one of ['r2', 'mae', 'mse']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e7127",
   "metadata": {},
   "source": [
    "## 3.2 Purged Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purged_cv(model, X, y, n_splits=6, verbose=True, purge=True, scorer=scorer, return_metric=\"r2\"):\n",
    "    \n",
    "    n = len(X)\n",
    "    fold_size = n // n_splits\n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i < n_splits - 1 else n\n",
    "        test_idx = np.arange(test_start, test_end)\n",
    "\n",
    "        purge_idx = []\n",
    "        if purge:\n",
    "            if i > 0:\n",
    "                purge_idx.extend(range((i - 1) * fold_size, test_start))\n",
    "            if i < n_splits - 1:\n",
    "                purge_idx.extend(range(test_end, min((i + 2) * fold_size, n)))\n",
    "\n",
    "        train_idx = np.setdiff1d(np.arange(n), np.concatenate([test_idx, purge_idx]) if purge else test_idx)\n",
    "\n",
    "        if len(train_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        est = clone(model)\n",
    "\n",
    "        if isinstance(est, LinearRegression) or isinstance(est, Lasso) or isinstance(est, Ridge) or isinstance(est, ElasticNet) or isinstance(est, ARDRegression):\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            est.fit(X_train, y_train)\n",
    "\n",
    "        elif isinstance(est, XGBRegressor):\n",
    "\n",
    "            if len(X_test) > 0:\n",
    "                est.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_test, y_test)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            else:\n",
    "                est.fit(X_train, y_train)\n",
    "        else:\n",
    "            est.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        y_pred = est.predict(X_test)\n",
    "\n",
    "        if verbose:\n",
    "            score_val = scorer(y_pred, y_test, label=f\"Fold {i}\", verbose=verbose, plot=False, return_metric=return_metric)\n",
    "        \n",
    "        if return_metric == \"r2\":\n",
    "            score_val = r2_score(y_test, y_pred)\n",
    "        elif return_metric == \"mae\":\n",
    "            score_val = mean_absolute_error(y_test, y_pred)\n",
    "        elif return_metric == \"mse\":\n",
    "            score_val = mean_squared_error(y_test, y_pred)\n",
    "        else:\n",
    "            raise ValueError(\"return_metric must be one of ['r2', 'mae', 'mse']\")\n",
    "\n",
    "\n",
    "        all_scores.append(score_val)\n",
    "\n",
    "    return np.mean(all_scores) if all_scores else None\n",
    "\n",
    "def purged_cv_shap_topk(model, X, y, n_splits=6, k=10, purge=True, scorer=None, return_metric=\"r2\", verbose=True):\n",
    "    n = len(X)\n",
    "    fold_size = n // n_splits\n",
    "    all_scores = []\n",
    "    top_features_per_fold = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i < n_splits - 1 else n\n",
    "        test_idx = np.arange(test_start, test_end)\n",
    "\n",
    "        purge_idx = []\n",
    "        if purge:\n",
    "            if i > 0:\n",
    "                purge_idx.extend(range((i - 1) * fold_size, test_start))\n",
    "            if i < n_splits - 1:\n",
    "                purge_idx.extend(range(test_end, min((i + 2) * fold_size, n)))\n",
    "\n",
    "        train_idx = np.setdiff1d(np.arange(n), np.concatenate([test_idx, purge_idx]) if purge else test_idx)\n",
    "        if len(train_idx) == 0:\n",
    "            continue\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        est = clone(model)\n",
    "\n",
    "        if isinstance(est, LinearRegression) or isinstance(est, LassoCV) or isinstance(est, Ridge) or isinstance(est, ElasticNet):\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            est.fit(X_train, y_train)\n",
    "\n",
    "        # XGBRegressor fit\n",
    "        elif isinstance(est, XGBRegressor):\n",
    "            if len(X_test) > 0:\n",
    "                est.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_test, y_test)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            else:\n",
    "                est.fit(X_train, y_train)\n",
    "\n",
    "        else:\n",
    "            est.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = est.predict(X_test)\n",
    "        if verbose and scorer is not None:\n",
    "            score_val = scorer(y_pred, y_test, label=f\"Fold {i}\", verbose=verbose, plot=False, return_metric=return_metric)\n",
    "        else:\n",
    "            from sklearn.metrics import r2_score\n",
    "            score_val = r2_score(y_test, y_pred)\n",
    "        all_scores.append(score_val)\n",
    "\n",
    "        explainer = shap.Explainer(est, X_train)\n",
    "        shap_values = explainer(X_train) \n",
    "\n",
    "        shap_mean_abs = np.abs(shap_values.values).mean(axis=0)\n",
    "        feature_importance = pd.Series(shap_mean_abs, index=X_train.columns)\n",
    "        top_features = feature_importance.sort_values(ascending=False).head(k).index.tolist()\n",
    "        top_features_per_fold.append(top_features)\n",
    "\n",
    "    mean_score = np.mean(all_scores) if all_scores else None\n",
    "    return mean_score, top_features_per_fold\n",
    "\n",
    "def purged_cv_predict_only(model, X, y, n_splits=6, verbose=True, purge=True, scorer=None, return_metric=\"r2\", scaler=None):\n",
    "    n = len(X)\n",
    "    fold_size = n // n_splits\n",
    "    all_scores = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i < n_splits - 1 else n\n",
    "        test_idx = np.arange(test_start, test_end)\n",
    "\n",
    "        purge_idx = []\n",
    "        if purge:\n",
    "            if i > 0:\n",
    "                purge_idx.extend(range((i - 1) * fold_size, test_start))\n",
    "            if i < n_splits - 1:\n",
    "                purge_idx.extend(range(test_end, min((i + 2) * fold_size, n)))\n",
    "\n",
    "        train_idx = np.setdiff1d(np.arange(n), np.concatenate([test_idx, purge_idx]) if purge else test_idx)\n",
    "\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        if isinstance(model, (LinearRegression, Lasso)):\n",
    "            if scaler is None:\n",
    "                raise ValueError(\"A fitted scaler must be provided for linear models.\")\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        if scorer:\n",
    "            score_val = scorer(y_pred, y_test, label=f\"Fold {i}\", verbose=verbose, plot=False, return_metric=return_metric)\n",
    "        else:\n",
    "            score_val = r2_score(y_test, y_pred)\n",
    "\n",
    "        all_scores.append(score_val)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {i}/{n_splits} → test size: {len(X_test)}, score: {score_val:.4f}\")\n",
    "\n",
    "    return np.mean(all_scores) if all_scores else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12afb9",
   "metadata": {},
   "source": [
    "# 4. Full Dataset Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88617d",
   "metadata": {},
   "source": [
    "## 4.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "470fafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Report for: Fold 0\n",
      "MAE: 1.0311\n",
      "MSE: 2.3691\n",
      "R^2: -1.2586\n",
      "Regression Report for: Fold 1\n",
      "MAE: 0.9403\n",
      "MSE: 1.6502\n",
      "R^2: -0.7209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpurged_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLinearRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurge\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mpurged_cv\u001b[39m\u001b[34m(model, X, y, n_splits, verbose, purge, scorer, return_metric)\u001b[39m\n\u001b[32m     31\u001b[39m     X_train = scaler.fit_transform(X_train)\n\u001b[32m     32\u001b[39m     X_test = scaler.transform(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43mest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(est, XGBRegressor):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_test) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/drw/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/drw/lib/python3.11/site-packages/sklearn/linear_model/_base.py:701\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# cut-off ratio for small singular values\u001b[39;00m\n\u001b[32m    700\u001b[39m     cond = \u001b[38;5;28mmax\u001b[39m(X.shape) * np.finfo(X.dtype).eps\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_, _, \u001b[38;5;28mself\u001b[39m.rank_, \u001b[38;5;28mself\u001b[39m.singular_ = \u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_ = \u001b[38;5;28mself\u001b[39m.coef_.T\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/drw/lib/python3.11/site-packages/scipy/_lib/_util.py:1226\u001b[39m, in \u001b[36m_apply_over_batch.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1224\u001b[39m \u001b[38;5;66;03m# Early exit if call is not batched\u001b[39;00m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(batch_shapes):\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mother_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[38;5;66;03m# Determine broadcasted batch shape\u001b[39;00m\n\u001b[32m   1229\u001b[39m batch_shape = np.broadcast_shapes(*batch_shapes)  \u001b[38;5;66;03m# Gives OK error message\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/drw/lib/python3.11/site-packages/scipy/linalg/_basic.py:1495\u001b[39m, in \u001b[36mlstsq\u001b[39m\u001b[34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m real_data:\n\u001b[32m   1494\u001b[39m     lwork, iwork = _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     x, s, rank, info = \u001b[43mlapack_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43miwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# complex data\u001b[39;00m\n\u001b[32m   1498\u001b[39m     lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n\u001b[32m   1499\u001b[39m                                          nrhs, cond)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "purged_cv(LinearRegression(), X, y, n_splits=6, purge=True, scorer=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a7175",
   "metadata": {},
   "source": [
    "## 4.2 Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c960fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"reg:pseudohubererror\",\n",
    "    \"learning_rate\": 0.01,       \n",
    "    \"n_estimators\": 2000,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"max_depth\": 4,              \n",
    "    \"gamma\": 1,                  \n",
    "    \"tree_method\": \"hist\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"eval_metric\": \"rmse\"\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(**params)\n",
    "#purged_cv(xgb_model, X, y, n_splits=6, purge=True, scorer=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30418356",
   "metadata": {},
   "source": [
    "# 5. Initial Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "02a9eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spearman_corr_mat.pkl\", \"rb\") as f:\n",
    "    corr_mat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "67932ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = X.corrwith(y, method='pearson')\n",
    "top_20_corrs = corrs.abs().sort_values(ascending=False).head(20).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "73c8c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 262616/262945 [11:46<00:00]        "
     ]
    }
   ],
   "source": [
    "score, top_feats = purged_cv_shap_topk(xgb_model, X, y, n_splits=6, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e139a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in union: 102\n"
     ]
    }
   ],
   "source": [
    "all_lists = top_feats + [['bid_qty', 'ask_qty', 'buy_qty', 'sell_qty', 'volume']] + [top_20_corrs]\n",
    "union_feats = list(set().union(*all_lists))\n",
    "\n",
    "print(f\"Number of features in union: {len(union_feats)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "656a214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_features(X, y, features, corr_thresh=0.9, target_corr_thresh=1e-4):\n",
    "\n",
    "    X_sub = X[features].copy()\n",
    "\n",
    "    target_corrs = X_sub.corrwith(y, method='pearson').abs()\n",
    "    filtered = target_corrs[target_corrs >= target_corr_thresh].index.tolist()\n",
    "    X_sub = X_sub[filtered]\n",
    "\n",
    "    corr_matrix = X_sub.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > corr_thresh)]\n",
    "    filtered_features = [f for f in X_sub.columns if f not in to_drop]\n",
    "\n",
    "    return filtered_features\n",
    "\n",
    "filtered = filter_features(X, y, union_feats, 0.9, 1e-4)\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5debcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X, y, max_features=None, threshold=0.0005, n_splits=6):\n",
    "    remaining_features = list(X.columns)\n",
    "    selected_features = []\n",
    "    scores = []\n",
    "    best_score = -float('inf')\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores_candidates = {}\n",
    "        \n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            model = LinearRegression()\n",
    "            score = purged_cv(model, X[current_features], y, n_splits=n_splits, verbose=False)\n",
    "            scores_candidates[feature] = score\n",
    "        \n",
    "        best_candidate = max(scores_candidates, key=scores_candidates.get)\n",
    "        candidate_score = scores_candidates[best_candidate]\n",
    "        \n",
    "        if candidate_score - best_score > threshold:\n",
    "            selected_features.append(best_candidate)\n",
    "            remaining_features.remove(best_candidate)\n",
    "            scores.append(candidate_score)\n",
    "            best_score = candidate_score\n",
    "            print(f\"Selected: {best_candidate}, CV score: {candidate_score:.4f}\")\n",
    "            \n",
    "            if max_features and len(selected_features) >= max_features:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return selected_features, scores\n",
    "\n",
    "#selected_features, scores = forward_selection(X, y, max_features=20, n_splits=6)\n",
    "#print(\"Final selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efb50310",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curr_feats = selected_features + [\"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"]\n",
    "curr_feats = ['X752', 'X21', 'X271', 'X109', 'X759', 'X445', 'X331', 'X508', 'X203', 'X386', 'X462', 'X625', 'X191'] + [\"bid_qty\", \"ask_qty\", \"buy_qty\", \"sell_qty\", \"volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df69d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Report for: Fold 0\n",
      "MAE: 0.6232\n",
      "MSE: 1.0069\n",
      "R^2: 0.0400\n",
      "Regression Report for: Fold 1\n",
      "MAE: 0.6218\n",
      "MSE: 0.9304\n",
      "R^2: 0.0297\n",
      "Regression Report for: Fold 2\n",
      "MAE: 0.5806\n",
      "MSE: 0.9902\n",
      "R^2: 0.0181\n",
      "Regression Report for: Fold 3\n",
      "MAE: 0.6146\n",
      "MSE: 0.9894\n",
      "R^2: 0.0252\n",
      "Regression Report for: Fold 4\n",
      "MAE: 0.6839\n",
      "MSE: 0.9339\n",
      "R^2: 0.0186\n",
      "Regression Report for: Fold 5\n",
      "MAE: 0.7000\n",
      "MSE: 1.0985\n",
      "R^2: 0.0249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.026076031633525565)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purged_cv(LinearRegression(), X[curr_feats], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac04bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Report for: Fold 0\n",
      "MAE: 0.6232\n",
      "MSE: 1.0069\n",
      "R^2: 0.0400\n",
      "Regression Report for: Fold 1\n",
      "MAE: 0.6218\n",
      "MSE: 0.9304\n",
      "R^2: 0.0297\n",
      "Regression Report for: Fold 2\n",
      "MAE: 0.5806\n",
      "MSE: 0.9902\n",
      "R^2: 0.0181\n",
      "Regression Report for: Fold 3\n",
      "MAE: 0.6146\n",
      "MSE: 0.9894\n",
      "R^2: 0.0252\n",
      "Regression Report for: Fold 4\n",
      "MAE: 0.6839\n",
      "MSE: 0.9339\n",
      "R^2: 0.0186\n",
      "Regression Report for: Fold 5\n",
      "MAE: 0.7000\n",
      "MSE: 1.0985\n",
      "R^2: 0.0249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.026076068201283942)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purged_cv(Ridge(alpha=1), X[curr_feats], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b412bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"booster\": \"gbtree\",           \n",
    "    \"tree_method\": \"hist\",          \n",
    "    \"learning_rate\": 0.007101297601522795,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"subsample\": 0.010008709882592429,\n",
    "    \"colsample_bytree\": 0.45890808231133295,\n",
    "    \"gamma\": 3.541694744811049,\n",
    "    \"reg_lambda\": 40.91405116528808,\n",
    "    \"reg_alpha\": 4.603129764500413,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"random_state\": 42,\n",
    "    \"verbosity\": 0\n",
    "}\n",
    "\n",
    "#purged_cv(XGBRegressor(**params), X[curr_feats], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d89b3",
   "metadata": {},
   "source": [
    "# 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db1243",
   "metadata": {},
   "source": [
    "## Feature Expansion Plan\n",
    "\n",
    "### Step 1: Linear Combinations\n",
    "- Generate only linear combinations of original features (e.g., sums, differences, weighted sums).  \n",
    "- **Feature Selection:**  \n",
    "  - Filter features based on correlation with the target (threshold, e.g., |corr| > 0.01).  \n",
    "  - Optionally, remove highly collinear features (|corr| > 0.9).  \n",
    "\n",
    "### Step 2: 2nd-Order Combinations\n",
    "- Generate pairwise interactions (products, ratios, differences) **only from original features**.  \n",
    "- **Feature Selection:**  \n",
    "  - Apply univariate filter (correlation or mutual information with target).  \n",
    "  - Optional: apply a wrapper method (stepwise forward selection or Lasso) to select top features.  \n",
    "\n",
    "### Step 3: 3rd-Order Combinations\n",
    "- Generate triplet interactions **only from original features**.  \n",
    "- **Feature Selection:**  \n",
    "  - Use univariate filter first.  \n",
    "  - Then apply a multivariate feature selection method:  \n",
    "    - Lasso regression (for linear effects), or  \n",
    "    - Tree-based importance (e.g., XGBoost SHAP values) to pick top-k features.  \n",
    "\n",
    "**Notes:**  \n",
    "- At each stage, **do not feed expanded features from previous stages** into the next expansion; always start from original features.  \n",
    "- Keep track of selected features at each stage to avoid exponential growth.  \n",
    "- Always apply correlation thresholding after selection to reduce redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a337d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feats = curr_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115f22b",
   "metadata": {},
   "source": [
    "## 6.1 Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9d99f",
   "metadata": {},
   "source": [
    "## 6.2 Correlation Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cbe251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_feature_selection(X, y, degree=3, target_threshold=0.05, redundancy_threshold=0.85):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    feature_names = poly.get_feature_names_out(X.columns)\n",
    "    X_poly = pd.DataFrame(X_poly, columns=feature_names, index=X.index)\n",
    "    \n",
    "    target_corr = X_poly.corrwith(y).abs()\n",
    "    keep = target_corr[target_corr >= target_threshold].index\n",
    "    X_filtered = X_poly[keep]\n",
    "    target_corr = target_corr[keep]  \n",
    "    \n",
    "    corr_matrix = X_filtered.corr().abs()\n",
    "    upper = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    to_drop = set()\n",
    "    \n",
    "    for i, f1 in enumerate(corr_matrix.columns):\n",
    "        for j, f2 in enumerate(corr_matrix.columns):\n",
    "            if upper[i, j] and corr_matrix.iloc[i, j] > redundancy_threshold:\n",
    "                if target_corr[f1] < target_corr[f2]:\n",
    "                    to_drop.add(f1)\n",
    "                else:\n",
    "                    to_drop.add(f2)\n",
    "    \n",
    "    selected_features = [f for f in X_filtered.columns if f not in to_drop]\n",
    "    return X_filtered[selected_features], selected_features\n",
    "\n",
    "\n",
    "filtered_df, curr_feats = polynomial_feature_selection(X[original_feats], y, target_threshold=1e-4, redundancy_threshold=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e0b0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X752', 'X21', 'X271', 'X109', 'X759', 'X445', 'X331', 'X508', 'X203', 'X386', 'X462', 'X625', 'X191', 'bid_qty', 'ask_qty', 'sell_qty', 'X752^2', 'X752 X21', 'X752 X271', 'X752 X109', 'X752 X759', 'X752 X445', 'X752 X331', 'X752 X508', 'X752 X203', 'X752 X386', 'X752 X462', 'X752 X625', 'X752 X191', 'X752 bid_qty', 'X752 ask_qty', 'X752 buy_qty', 'X21^2', 'X21 X271', 'X21 X109', 'X21 X759', 'X21 X445', 'X21 X331', 'X21 X508', 'X21 X203', 'X21 X386', 'X21 X462', 'X21 X625', 'X21 X191', 'X21 bid_qty', 'X21 ask_qty', 'X21 sell_qty', 'X271^2', 'X271 X109', 'X271 X759', 'X271 X445', 'X271 X331', 'X271 X508', 'X271 X203', 'X271 X386', 'X271 X462', 'X271 X625', 'X271 X191', 'X271 bid_qty', 'X271 ask_qty', 'X271 volume', 'X109^2', 'X109 X759', 'X109 X445', 'X109 X331', 'X109 X508', 'X109 X203', 'X109 X386', 'X109 X462', 'X109 X625', 'X109 X191', 'X109 bid_qty', 'X109 ask_qty', 'X109 volume', 'X759^2', 'X759 X445', 'X759 X331', 'X759 X508', 'X759 X203', 'X759 X386', 'X759 X462', 'X759 X625', 'X759 X191', 'X759 bid_qty', 'X759 ask_qty', 'X759 volume', 'X445^2', 'X445 X331', 'X445 X508', 'X445 X203', 'X445 X386', 'X445 X462', 'X445 X625', 'X445 X191', 'X445 bid_qty', 'X445 ask_qty', 'X445 sell_qty', 'X331^2', 'X331 X508', 'X331 X203', 'X331 X386', 'X331 X462', 'X331 X625', 'X331 X191', 'X331 bid_qty', 'X331 ask_qty', 'X331 volume', 'X508^2', 'X508 X203', 'X508 X386', 'X508 X462', 'X508 X625', 'X508 X191', 'X508 bid_qty', 'X508 ask_qty', 'X508 volume', 'X203^2', 'X203 X386', 'X203 X462', 'X203 X625', 'X203 X191', 'X203 bid_qty', 'X203 ask_qty', 'X203 sell_qty', 'X386^2', 'X386 X462', 'X386 X625', 'X386 X191', 'X386 bid_qty', 'X386 ask_qty', 'X386 buy_qty', 'X462^2', 'X462 X625', 'X462 X191', 'X462 bid_qty', 'X462 ask_qty', 'X462 volume', 'X625^2', 'X625 X191', 'X625 bid_qty', 'X625 ask_qty', 'X625 volume', 'X191^2', 'X191 bid_qty', 'X191 ask_qty', 'X191 sell_qty', 'bid_qty^2', 'bid_qty ask_qty', 'bid_qty buy_qty', 'ask_qty buy_qty', 'sell_qty^2', 'X752^3', 'X752^2 X21', 'X752^2 X271', 'X752^2 X109', 'X752^2 X759', 'X752^2 X445', 'X752^2 X331', 'X752^2 X508', 'X752^2 X203', 'X752^2 X386', 'X752^2 X462', 'X752^2 X625', 'X752^2 X191', 'X752^2 bid_qty', 'X752^2 ask_qty', 'X752^2 volume', 'X752 X21^2', 'X752 X21 X271', 'X752 X21 X109', 'X752 X21 X759', 'X752 X21 X445', 'X752 X21 X331', 'X752 X21 X508', 'X752 X21 X203', 'X752 X21 X386', 'X752 X21 X462', 'X752 X21 X625', 'X752 X21 X191', 'X752 X21 bid_qty', 'X752 X21 ask_qty', 'X752 X21 buy_qty', 'X752 X271^2', 'X752 X271 X109', 'X752 X271 X759', 'X752 X271 X445', 'X752 X271 X331', 'X752 X271 X508', 'X752 X271 X203', 'X752 X271 X386', 'X752 X271 X462', 'X752 X271 X625', 'X752 X271 X191', 'X752 X271 bid_qty', 'X752 X271 ask_qty', 'X752 X271 buy_qty', 'X752 X109^2', 'X752 X109 X759', 'X752 X109 X445', 'X752 X109 X331', 'X752 X109 X508', 'X752 X109 X203', 'X752 X109 X386', 'X752 X109 X462', 'X752 X109 X625', 'X752 X109 X191', 'X752 X109 bid_qty', 'X752 X109 ask_qty', 'X752 X109 buy_qty', 'X752 X759^2', 'X752 X759 X445', 'X752 X759 X331', 'X752 X759 X508', 'X752 X759 X203', 'X752 X759 X386', 'X752 X759 X462', 'X752 X759 X625', 'X752 X759 X191', 'X752 X759 bid_qty', 'X752 X759 ask_qty', 'X752 X759 buy_qty', 'X752 X445^2', 'X752 X445 X331', 'X752 X445 X508', 'X752 X445 X203', 'X752 X445 X386', 'X752 X445 X462', 'X752 X445 X625', 'X752 X445 X191', 'X752 X445 bid_qty', 'X752 X445 ask_qty', 'X752 X445 buy_qty', 'X752 X331^2', 'X752 X331 X508', 'X752 X331 X203', 'X752 X331 X386', 'X752 X331 X462', 'X752 X331 X625', 'X752 X331 X191', 'X752 X331 bid_qty', 'X752 X331 ask_qty', 'X752 X331 buy_qty', 'X752 X508^2', 'X752 X508 X203', 'X752 X508 X386', 'X752 X508 X462', 'X752 X508 X625', 'X752 X508 X191', 'X752 X508 bid_qty', 'X752 X508 ask_qty', 'X752 X508 sell_qty', 'X752 X203^2', 'X752 X203 X386', 'X752 X203 X462', 'X752 X203 X625', 'X752 X203 X191', 'X752 X203 bid_qty', 'X752 X203 ask_qty', 'X752 X203 volume', 'X752 X386^2', 'X752 X386 X462', 'X752 X386 X625', 'X752 X386 X191', 'X752 X386 bid_qty', 'X752 X386 ask_qty', 'X752 X386 buy_qty', 'X752 X462^2', 'X752 X462 X625', 'X752 X462 X191', 'X752 X462 bid_qty', 'X752 X462 ask_qty', 'X752 X462 buy_qty', 'X752 X625^2', 'X752 X625 X191', 'X752 X625 bid_qty', 'X752 X625 ask_qty', 'X752 X625 buy_qty', 'X752 X191^2', 'X752 X191 bid_qty', 'X752 X191 ask_qty', 'X752 X191 volume', 'X752 bid_qty^2', 'X752 bid_qty ask_qty', 'X752 bid_qty buy_qty', 'X752 ask_qty^2', 'X752 ask_qty sell_qty', 'X752 buy_qty volume', 'X21^3', 'X21^2 X271', 'X21^2 X109', 'X21^2 X759', 'X21^2 X445', 'X21^2 X331', 'X21^2 X508', 'X21^2 X203', 'X21^2 X386', 'X21^2 X462', 'X21^2 X625', 'X21^2 X191', 'X21^2 bid_qty', 'X21^2 ask_qty', 'X21^2 sell_qty', 'X21 X271^2', 'X21 X271 X109', 'X21 X271 X759', 'X21 X271 X445', 'X21 X271 X331', 'X21 X271 X508', 'X21 X271 X203', 'X21 X271 X386', 'X21 X271 X462', 'X21 X271 X625', 'X21 X271 X191', 'X21 X271 bid_qty', 'X21 X271 ask_qty', 'X21 X271 sell_qty', 'X21 X109^2', 'X21 X109 X759', 'X21 X109 X445', 'X21 X109 X331', 'X21 X109 X508', 'X21 X109 X203', 'X21 X109 X386', 'X21 X109 X462', 'X21 X109 X625', 'X21 X109 X191', 'X21 X109 bid_qty', 'X21 X109 ask_qty', 'X21 X109 sell_qty', 'X21 X759^2', 'X21 X759 X445', 'X21 X759 X331', 'X21 X759 X508', 'X21 X759 X203', 'X21 X759 X386', 'X21 X759 X462', 'X21 X759 X625', 'X21 X759 X191', 'X21 X759 bid_qty', 'X21 X759 ask_qty', 'X21 X759 sell_qty', 'X21 X445^2', 'X21 X445 X331', 'X21 X445 X508', 'X21 X445 X203', 'X21 X445 X386', 'X21 X445 X462', 'X21 X445 X625', 'X21 X445 X191', 'X21 X445 bid_qty', 'X21 X445 ask_qty', 'X21 X445 buy_qty', 'X21 X331^2', 'X21 X331 X508', 'X21 X331 X203', 'X21 X331 X386', 'X21 X331 X462', 'X21 X331 X625', 'X21 X331 X191', 'X21 X331 bid_qty', 'X21 X331 ask_qty', 'X21 X331 volume', 'X21 X508^2', 'X21 X508 X203', 'X21 X508 X386', 'X21 X508 X462', 'X21 X508 X625', 'X21 X508 X191', 'X21 X508 bid_qty', 'X21 X508 ask_qty', 'X21 X508 volume', 'X21 X203^2', 'X21 X203 X386', 'X21 X203 X462', 'X21 X203 X625', 'X21 X203 X191', 'X21 X203 bid_qty', 'X21 X203 ask_qty', 'X21 X203 buy_qty', 'X21 X203 sell_qty', 'X21 X386^2', 'X21 X386 X462', 'X21 X386 X625', 'X21 X386 X191', 'X21 X386 bid_qty', 'X21 X386 ask_qty', 'X21 X386 buy_qty', 'X21 X462^2', 'X21 X462 X625', 'X21 X462 X191', 'X21 X462 bid_qty', 'X21 X462 ask_qty', 'X21 X462 volume', 'X21 X625^2', 'X21 X625 X191', 'X21 X625 bid_qty', 'X21 X625 ask_qty', 'X21 X625 sell_qty', 'X21 X191^2', 'X21 X191 bid_qty', 'X21 X191 ask_qty', 'X21 X191 sell_qty', 'X21 bid_qty^2', 'X21 bid_qty ask_qty', 'X21 bid_qty sell_qty', 'X21 ask_qty^2', 'X21 ask_qty buy_qty', 'X21 buy_qty^2', 'X21 sell_qty^2', 'X271^3', 'X271^2 X109', 'X271^2 X759', 'X271^2 X445', 'X271^2 X331', 'X271^2 X508', 'X271^2 X203', 'X271^2 X386', 'X271^2 X462', 'X271^2 X625', 'X271^2 X191', 'X271^2 bid_qty', 'X271^2 ask_qty', 'X271^2 sell_qty', 'X271 X109^2', 'X271 X109 X759', 'X271 X109 X445', 'X271 X109 X331', 'X271 X109 X508', 'X271 X109 X203', 'X271 X109 X386', 'X271 X109 X462', 'X271 X109 X625', 'X271 X109 X191', 'X271 X109 bid_qty', 'X271 X109 ask_qty', 'X271 X109 buy_qty', 'X271 X759^2', 'X271 X759 X445', 'X271 X759 X331', 'X271 X759 X508', 'X271 X759 X203', 'X271 X759 X386', 'X271 X759 X462', 'X271 X759 X625', 'X271 X759 X191', 'X271 X759 bid_qty', 'X271 X759 ask_qty', 'X271 X759 buy_qty', 'X271 X445^2', 'X271 X445 X331', 'X271 X445 X508', 'X271 X445 X203', 'X271 X445 X386', 'X271 X445 X462', 'X271 X445 X625', 'X271 X445 X191', 'X271 X445 bid_qty', 'X271 X445 ask_qty', 'X271 X445 buy_qty', 'X271 X331^2', 'X271 X331 X508', 'X271 X331 X203', 'X271 X331 X386', 'X271 X331 X462', 'X271 X331 X625', 'X271 X331 X191', 'X271 X331 bid_qty', 'X271 X331 ask_qty', 'X271 X331 sell_qty', 'X271 X508^2', 'X271 X508 X203', 'X271 X508 X386', 'X271 X508 X462', 'X271 X508 X625', 'X271 X508 X191', 'X271 X508 bid_qty', 'X271 X508 ask_qty', 'X271 X508 buy_qty', 'X271 X203^2', 'X271 X203 X386', 'X271 X203 X462', 'X271 X203 X625', 'X271 X203 X191', 'X271 X203 bid_qty', 'X271 X203 ask_qty', 'X271 X203 buy_qty', 'X271 X386^2', 'X271 X386 X462', 'X271 X386 X625', 'X271 X386 X191', 'X271 X386 bid_qty', 'X271 X386 ask_qty', 'X271 X386 buy_qty', 'X271 X462^2', 'X271 X462 X625', 'X271 X462 X191', 'X271 X462 bid_qty', 'X271 X462 ask_qty', 'X271 X462 buy_qty', 'X271 X625^2', 'X271 X625 X191', 'X271 X625 bid_qty', 'X271 X625 ask_qty', 'X271 X625 buy_qty', 'X271 X625 sell_qty', 'X271 X191^2', 'X271 X191 bid_qty', 'X271 X191 ask_qty', 'X271 X191 buy_qty', 'X271 bid_qty^2', 'X271 bid_qty ask_qty', 'X271 bid_qty buy_qty', 'X271 ask_qty^2', 'X271 ask_qty buy_qty', 'X271 buy_qty sell_qty', 'X109^3', 'X109^2 X759', 'X109^2 X445', 'X109^2 X331', 'X109^2 X508', 'X109^2 X203', 'X109^2 X386', 'X109^2 X462', 'X109^2 X625', 'X109^2 X191', 'X109^2 bid_qty', 'X109^2 ask_qty', 'X109^2 buy_qty', 'X109 X759^2', 'X109 X759 X445', 'X109 X759 X331', 'X109 X759 X508', 'X109 X759 X203', 'X109 X759 X386', 'X109 X759 X462', 'X109 X759 X625', 'X109 X759 X191', 'X109 X759 bid_qty', 'X109 X759 ask_qty', 'X109 X759 buy_qty', 'X109 X445^2', 'X109 X445 X331', 'X109 X445 X508', 'X109 X445 X203', 'X109 X445 X386', 'X109 X445 X462', 'X109 X445 X625', 'X109 X445 X191', 'X109 X445 bid_qty', 'X109 X445 ask_qty', 'X109 X445 buy_qty', 'X109 X331^2', 'X109 X331 X508', 'X109 X331 X203', 'X109 X331 X386', 'X109 X331 X462', 'X109 X331 X625', 'X109 X331 X191', 'X109 X331 bid_qty', 'X109 X331 ask_qty', 'X109 X331 buy_qty', 'X109 X508^2', 'X109 X508 X203', 'X109 X508 X386', 'X109 X508 X462', 'X109 X508 X625', 'X109 X508 X191', 'X109 X508 bid_qty', 'X109 X508 ask_qty', 'X109 X508 sell_qty', 'X109 X203^2', 'X109 X203 X386', 'X109 X203 X462', 'X109 X203 X625', 'X109 X203 X191', 'X109 X203 bid_qty', 'X109 X203 ask_qty', 'X109 X203 sell_qty', 'X109 X386^2', 'X109 X386 X462', 'X109 X386 X625', 'X109 X386 X191', 'X109 X386 bid_qty', 'X109 X386 ask_qty', 'X109 X386 buy_qty', 'X109 X462^2', 'X109 X462 X625', 'X109 X462 X191', 'X109 X462 bid_qty', 'X109 X462 ask_qty', 'X109 X462 buy_qty', 'X109 X462 sell_qty', 'X109 X625^2', 'X109 X625 X191', 'X109 X625 bid_qty', 'X109 X625 ask_qty', 'X109 X625 buy_qty', 'X109 X191^2', 'X109 X191 bid_qty', 'X109 X191 ask_qty', 'X109 X191 buy_qty', 'X109 bid_qty^2', 'X109 bid_qty ask_qty', 'X109 bid_qty sell_qty', 'X109 ask_qty^2', 'X109 ask_qty buy_qty', 'X109 buy_qty sell_qty', 'X759^3', 'X759^2 X445', 'X759^2 X331', 'X759^2 X508', 'X759^2 X203', 'X759^2 X386', 'X759^2 X462', 'X759^2 X625', 'X759^2 X191', 'X759^2 bid_qty', 'X759^2 ask_qty', 'X759^2 buy_qty', 'X759 X445^2', 'X759 X445 X331', 'X759 X445 X508', 'X759 X445 X203', 'X759 X445 X386', 'X759 X445 X462', 'X759 X445 X625', 'X759 X445 X191', 'X759 X445 bid_qty', 'X759 X445 ask_qty', 'X759 X445 buy_qty', 'X759 X445 sell_qty', 'X759 X331^2', 'X759 X331 X508', 'X759 X331 X203', 'X759 X331 X386', 'X759 X331 X462', 'X759 X331 X625', 'X759 X331 X191', 'X759 X331 bid_qty', 'X759 X331 ask_qty', 'X759 X331 buy_qty', 'X759 X508^2', 'X759 X508 X203', 'X759 X508 X386', 'X759 X508 X462', 'X759 X508 X625', 'X759 X508 X191', 'X759 X508 bid_qty', 'X759 X508 ask_qty', 'X759 X508 buy_qty', 'X759 X203^2', 'X759 X203 X386', 'X759 X203 X462', 'X759 X203 X625', 'X759 X203 X191', 'X759 X203 bid_qty', 'X759 X203 ask_qty', 'X759 X203 buy_qty', 'X759 X386^2', 'X759 X386 X462', 'X759 X386 X625', 'X759 X386 X191', 'X759 X386 bid_qty', 'X759 X386 ask_qty', 'X759 X386 buy_qty', 'X759 X462^2', 'X759 X462 X191', 'X759 X462 bid_qty', 'X759 X462 ask_qty', 'X759 X625^2', 'X759 X625 X191', 'X759 X625 bid_qty', 'X759 X625 ask_qty', 'X759 X625 buy_qty', 'X759 X191^2', 'X759 X191 bid_qty', 'X759 X191 ask_qty', 'X759 X191 buy_qty', 'X759 bid_qty^2', 'X759 bid_qty ask_qty', 'X759 bid_qty buy_qty', 'X759 ask_qty^2', 'X759 ask_qty volume', 'X759 buy_qty sell_qty', 'X445^3', 'X445^2 X331', 'X445^2 X508', 'X445^2 X203', 'X445^2 X386', 'X445^2 X462', 'X445^2 X625', 'X445^2 X191', 'X445^2 bid_qty', 'X445^2 ask_qty', 'X445^2 buy_qty', 'X445 X331^2', 'X445 X331 X508', 'X445 X331 X203', 'X445 X331 X386', 'X445 X331 X462', 'X445 X331 X625', 'X445 X331 X191', 'X445 X331 bid_qty', 'X445 X331 ask_qty', 'X445 X331 buy_qty', 'X445 X508^2', 'X445 X508 X203', 'X445 X508 X386', 'X445 X508 X462', 'X445 X508 X625', 'X445 X508 X191', 'X445 X508 bid_qty', 'X445 X508 ask_qty', 'X445 X508 buy_qty', 'X445 X203^2', 'X445 X203 X386', 'X445 X203 X462', 'X445 X203 X625', 'X445 X203 X191', 'X445 X203 bid_qty', 'X445 X203 ask_qty', 'X445 X203 buy_qty', 'X445 X203 sell_qty', 'X445 X386^2', 'X445 X386 X462', 'X445 X386 X625', 'X445 X386 X191', 'X445 X386 bid_qty', 'X445 X386 ask_qty', 'X445 X386 buy_qty', 'X445 X462^2', 'X445 X462 X625', 'X445 X462 X191', 'X445 X462 bid_qty', 'X445 X462 ask_qty', 'X445 X462 buy_qty', 'X445 X462 sell_qty', 'X445 X625^2', 'X445 X625 X191', 'X445 X625 bid_qty', 'X445 X625 ask_qty', 'X445 X625 buy_qty', 'X445 X191^2', 'X445 X191 bid_qty', 'X445 X191 ask_qty', 'X445 X191 volume', 'X445 bid_qty^2', 'X445 bid_qty ask_qty', 'X445 bid_qty sell_qty', 'X445 ask_qty^2', 'X445 ask_qty buy_qty', 'X445 buy_qty sell_qty', 'X331^3', 'X331^2 X508', 'X331^2 X386', 'X331^2 X462', 'X331^2 X625', 'X331^2 X191', 'X331^2 bid_qty', 'X331^2 ask_qty', 'X331^2 sell_qty', 'X331 X508^2', 'X331 X508 X203', 'X331 X508 X386', 'X331 X508 X462', 'X331 X508 X625', 'X331 X508 X191', 'X331 X508 bid_qty', 'X331 X508 ask_qty', 'X331 X508 buy_qty', 'X331 X203^2', 'X331 X203 X386', 'X331 X203 X462', 'X331 X203 X625', 'X331 X203 X191', 'X331 X203 bid_qty', 'X331 X203 ask_qty', 'X331 X203 sell_qty', 'X331 X386^2', 'X331 X386 X462', 'X331 X386 X625', 'X331 X386 X191', 'X331 X386 bid_qty', 'X331 X386 ask_qty', 'X331 X386 buy_qty', 'X331 X462^2', 'X331 X462 X191', 'X331 X462 bid_qty', 'X331 X462 ask_qty', 'X331 X462 buy_qty', 'X331 X625^2', 'X331 X625 X191', 'X331 X625 bid_qty', 'X331 X625 ask_qty', 'X331 X625 buy_qty', 'X331 X191^2', 'X331 X191 bid_qty', 'X331 X191 ask_qty', 'X331 X191 buy_qty', 'X331 bid_qty ask_qty', 'X331 bid_qty buy_qty', 'X331 ask_qty^2', 'X331 ask_qty buy_qty', 'X331 buy_qty sell_qty', 'X508^3', 'X508^2 X203', 'X508^2 X386', 'X508^2 X462', 'X508^2 X625', 'X508^2 X191', 'X508^2 bid_qty', 'X508^2 ask_qty', 'X508^2 buy_qty', 'X508 X203^2', 'X508 X203 X386', 'X508 X203 X462', 'X508 X203 X625', 'X508 X203 X191', 'X508 X203 bid_qty', 'X508 X203 ask_qty', 'X508 X203 sell_qty', 'X508 X386^2', 'X508 X386 X462', 'X508 X386 X625', 'X508 X386 X191', 'X508 X386 bid_qty', 'X508 X386 ask_qty', 'X508 X386 buy_qty', 'X508 X462^2', 'X508 X462 X625', 'X508 X462 X191', 'X508 X462 bid_qty', 'X508 X462 ask_qty', 'X508 X462 sell_qty', 'X508 X625^2', 'X508 X625 X191', 'X508 X625 bid_qty', 'X508 X625 ask_qty', 'X508 X625 buy_qty', 'X508 X191^2', 'X508 X191 bid_qty', 'X508 X191 ask_qty', 'X508 X191 sell_qty', 'X508 bid_qty^2', 'X508 bid_qty ask_qty', 'X508 bid_qty volume', 'X508 ask_qty^2', 'X508 ask_qty buy_qty', 'X508 buy_qty sell_qty', 'X203^3', 'X203^2 X386', 'X203^2 X462', 'X203^2 X625', 'X203^2 X191', 'X203^2 bid_qty', 'X203^2 ask_qty', 'X203^2 volume', 'X203 X386^2', 'X203 X386 X462', 'X203 X386 X625', 'X203 X386 X191', 'X203 X386 bid_qty', 'X203 X386 ask_qty', 'X203 X386 volume', 'X203 X462^2', 'X203 X462 X625', 'X203 X462 X191', 'X203 X462 bid_qty', 'X203 X462 ask_qty', 'X203 X462 buy_qty', 'X203 X625^2', 'X203 X625 X191', 'X203 X625 bid_qty', 'X203 X625 ask_qty', 'X203 X625 sell_qty', 'X203 X191^2', 'X203 X191 bid_qty', 'X203 X191 buy_qty', 'X203 bid_qty^2', 'X203 bid_qty ask_qty', 'X203 bid_qty sell_qty', 'X203 ask_qty^2', 'X203 ask_qty sell_qty', 'X203 buy_qty sell_qty', 'X386^3', 'X386^2 X462', 'X386^2 X625', 'X386^2 X191', 'X386^2 bid_qty', 'X386^2 ask_qty', 'X386^2 buy_qty', 'X386 X462^2', 'X386 X462 X625', 'X386 X462 X191', 'X386 X462 bid_qty', 'X386 X462 ask_qty', 'X386 X462 buy_qty', 'X386 X625^2', 'X386 X625 X191', 'X386 X625 bid_qty', 'X386 X625 ask_qty', 'X386 X625 buy_qty', 'X386 X191^2', 'X386 X191 bid_qty', 'X386 X191 ask_qty', 'X386 X191 volume', 'X386 bid_qty^2', 'X386 bid_qty ask_qty', 'X386 bid_qty sell_qty', 'X386 ask_qty^2', 'X386 ask_qty buy_qty', 'X386 buy_qty sell_qty', 'X462^3', 'X462^2 X191', 'X462^2 bid_qty', 'X462^2 ask_qty', 'X462 X625^2', 'X462 X625 X191', 'X462 X625 bid_qty', 'X462 X625 ask_qty', 'X462 X625 buy_qty', 'X462 X191^2', 'X462 X191 bid_qty', 'X462 X191 ask_qty', 'X462 X191 buy_qty', 'X462 bid_qty^2', 'X462 bid_qty ask_qty', 'X462 bid_qty buy_qty', 'X462 ask_qty^2', 'X462 ask_qty buy_qty', 'X462 buy_qty sell_qty', 'X625^3', 'X625^2 X191', 'X625^2 bid_qty', 'X625^2 ask_qty', 'X625^2 buy_qty', 'X625 X191^2', 'X625 X191 bid_qty', 'X625 X191 ask_qty', 'X625 X191 buy_qty', 'X625 bid_qty^2', 'X625 bid_qty ask_qty', 'X625 bid_qty sell_qty', 'X625 ask_qty^2', 'X625 buy_qty sell_qty', 'X191^3', 'X191^2 bid_qty', 'X191^2 ask_qty', 'X191^2 buy_qty', 'X191 bid_qty^2', 'X191 bid_qty ask_qty', 'X191 bid_qty buy_qty', 'X191 ask_qty^2', 'X191 ask_qty volume', 'X191 sell_qty volume', 'bid_qty^2 sell_qty', 'bid_qty ask_qty sell_qty', 'bid_qty ask_qty volume', 'bid_qty buy_qty^2', 'bid_qty sell_qty^2', 'ask_qty^3', 'ask_qty^2 sell_qty', 'ask_qty buy_qty^2', 'buy_qty^2 sell_qty']\n"
     ]
    }
   ],
   "source": [
    "print(curr_feats)\n",
    "filtered_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ef03c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 350471/350588 [35:58<00:00]        "
     ]
    }
   ],
   "source": [
    "mean_score, top_k_feats = purged_cv_shap_topk(XGBRegressor(**params), filtered_df[curr_feats], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59222449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['volume', 'X21 sell_qty', 'X752^2 X21', 'X508', 'X109', 'bid_qty', 'X752 X508^2', 'X462', 'X752 X271 buy_qty', 'X759', 'X21^3', 'X386', 'X271 X508 ask_qty', 'X386 X625^2', 'X752 X271 X445', 'X331', 'X752 X331 ask_qty', 'sell_qty', 'X271', 'X752 buy_qty volume', 'X445', 'X271 X203 X462', 'X191', 'X203', 'X331 X203 X625', 'ask_qty', 'X203 X386 volume', 'X752^2 X271', 'X759 X445 X508', 'X752^2 X625', 'X752 X625^2', 'X752 X759^2', 'X508 X386 X462', 'X21 X271^2', 'X271 X445 X203', 'X752 X203^2', 'X21 X445 X386', 'X445 X625^2', 'X21 X508^2', 'X752', 'X625', 'X752 X331 buy_qty', 'X271 X508', 'X271 X445 ask_qty', 'X445 X203 X386', 'X21', 'X752 X445 X386', 'X752 X759 X625', 'buy_qty', 'X109^2 X759', 'X271^2 X331', 'X21 X191^2', 'X625^2', 'X445^3', 'X752 X109^2', 'X445 X386']\n",
      "0.002100587141845023\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = top_k_feats\n",
    "union_set = set().union(*list_of_lists)\n",
    "union_set = union_set.union(original_feats)\n",
    "union_list = list(union_set)\n",
    "print(union_list)\n",
    "print(mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d86081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_list = ['volume', 'X21 sell_qty', 'X752^2 X21', 'X508', 'X109', 'bid_qty', 'X752 X508^2', 'X462', 'X752 X271 buy_qty', 'X759', 'X21^3', 'X386', 'X271 X508 ask_qty', 'X386 X625^2', 'X752 X271 X445', 'X331', 'X752 X331 ask_qty', 'sell_qty', 'X271', 'X752 buy_qty volume', 'X445', 'X271 X203 X462', 'X191', 'X203', 'X331 X203 X625', 'ask_qty', 'X203 X386 volume', 'X752^2 X271', 'X759 X445 X508', 'X752^2 X625', 'X752 X625^2', 'X752 X759^2', 'X508 X386 X462', 'X21 X271^2', 'X271 X445 X203', 'X752 X203^2', 'X21 X445 X386', 'X445 X625^2', 'X21 X508^2', 'X752', 'X625', 'X752 X331 buy_qty', 'X271 X508', 'X271 X445 ask_qty', 'X445 X203 X386', 'X21', 'X752 X445 X386', 'X752 X759 X625', 'buy_qty', 'X109^2 X759', 'X271^2 X331', 'X21 X191^2', 'X625^2', 'X445^3', 'X752 X109^2', 'X445 X386']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbfa8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: X752, CV score: 0.0043\n",
      "Selected: X21, CV score: 0.0117\n",
      "Selected: X445^3, CV score: 0.0142\n",
      "Selected: X331, CV score: 0.0180\n",
      "Selected: X759, CV score: 0.0199\n",
      "Selected: X109, CV score: 0.0212\n",
      "Selected: X271, CV score: 0.0226\n",
      "Selected: X508, CV score: 0.0240\n",
      "Selected: X203, CV score: 0.0249\n",
      "Selected: X386, CV score: 0.0257\n",
      "Selected: X462, CV score: 0.0264\n",
      "Selected: X191, CV score: 0.0270\n",
      "Selected: X625, CV score: 0.0279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['X752',\n",
       "  'X21',\n",
       "  'X445^3',\n",
       "  'X331',\n",
       "  'X759',\n",
       "  'X109',\n",
       "  'X271',\n",
       "  'X508',\n",
       "  'X203',\n",
       "  'X386',\n",
       "  'X462',\n",
       "  'X191',\n",
       "  'X625'],\n",
       " [np.float64(0.004269965602407555),\n",
       "  np.float64(0.01169028461903221),\n",
       "  np.float64(0.014168241095493583),\n",
       "  np.float64(0.0180442318518416),\n",
       "  np.float64(0.019902084077476383),\n",
       "  np.float64(0.02117309612288069),\n",
       "  np.float64(0.02261888902935168),\n",
       "  np.float64(0.023954848478813462),\n",
       "  np.float64(0.024895834406202244),\n",
       "  np.float64(0.02574105525646873),\n",
       "  np.float64(0.026388425334610093),\n",
       "  np.float64(0.026959353285005667),\n",
       "  np.float64(0.027901281538071403)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_selection(X, y, max_features=40, threshold=0.0005, n_splits=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
